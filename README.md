# TestGenAI â€“ Complete Test Case Generator (Froth Test Ops)

ğŸš€ An AI-powered **Test Case Generator** that transforms plain-English requirements into structured test cases.  
It combines **OpenAI LLMs**, **vector similarity search (ChromaDB + Sentence Transformers)**, **caching**, and **audit logging** to deliver cost-efficient, reusable, and high-quality test artifacts.

---

## âœ¨ Features
- **OpenAI Integration** â€“ Generate comprehensive test cases with GPT models
- **Smart Token Management** â€“ Tracks usage, cost, and applies daily/monthly quotas
- **Caching** â€“ Prevents duplicate costs for repeated requirements
- **Vector Similarity** â€“ Finds and reuses similar requirements via embeddings
- **Local Fallback** â€“ Adapts existing cases if close matches exist
- **Audit Logging** â€“ JSONL logs for every request with metadata
- **User Quotas** â€“ Enforces limits and usage tracking per user

---

Requirements
	â€¢	Python 3.9+ (tested on 3.10/3.11)
	â€¢	Disk access for ./data (cache, quotas, logs, vector DB)
	â€¢	OpenAI API key (for generation mode)
 
``````



#Clone repo
git clone https://github.com/pritishpattanaik/test-ops-poc

cd testgenai

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install openai tiktoken sentence-transformers chromadb pandas numpy python-dotenv




#Configuration

Create a .env file in the project root:
OPENAI_API_KEY=sk-your-api-key

```
#Run the example script:
python3 rd_froth_testops.py

# check the cache status

# Run again and see the cache status whether its beign served from local or not ? 

``````

ğŸ“‚ Data & Logs
	â€¢	Cache: ./data/cache.json
	â€¢	Quotas: ./data/quotas.json
	â€¢	Audit Logs: ./data/audit_logs.jsonl
	â€¢	Vector DB: ./data/chroma_db/


 ğŸ“Š Quotas & Costs
	â€¢	Daily Limit: 10,000 tokens per user
	â€¢	Monthly Limit: 300,000 tokens per user
	â€¢	Pricing Reference:
	â€¢	gpt-3.5-turbo: $0.001 / 1K input, $0.002 / 1K output
	â€¢	gpt-4: $0.03 / 1K input, $0.06 / 1K output

â“ FAQ

Q: Can it run without OpenAI?
Yes. It will still serve results via cache and vector similarity if similar requirements exist.

Q: Where are test cases stored?
Each request is logged and cached locally; vector DB enables reusability.

Q: Can I add other LLM providers?
Yes, extend _call_openai_api() or add new providers with a similar interface.


ğŸ›£ï¸ Roadmap
	â€¢	ğŸ”— Support for Gemini & Anthropic Claude
	â€¢	ğŸ–¥ï¸ REST API wrapper with FastAPI
	â€¢	ğŸ“Š Web dashboard for usage & quota monitoring
	â€¢	ğŸ§ª Export test cases to CSV/Excel/JIRA

 ğŸ“œ License

